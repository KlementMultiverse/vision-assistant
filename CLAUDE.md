# Vision Assistant - Project Context for Claude

> **Last Updated:** 2026-02-07
> **Status:** Phase 1 Implementation Ready

---

## Quick Status

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VISION ASSISTANT                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  v2 (Complete)  â”‚  v3 (In Progress)                            â”‚
â”‚  âœ… Face Recog   â”‚  ğŸ”„ Phase 1: Foundation                      â”‚
â”‚  âœ… Person Det   â”‚  â³ Phase 2: Vision Intelligence             â”‚
â”‚  âœ… Tracking     â”‚  â³ Phase 3: Multi-Camera                    â”‚
â”‚  âœ… Tagging      â”‚  â³ Phase 4: Conversation                    â”‚
â”‚  âœ… Voice TTS    â”‚  â³ Phase 5: Telegram Bot                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Session Completion Log

### 2026-02-07: Architecture & Planning Session

| Task | Status | Output |
|------|--------|--------|
| Architecture document | âœ… Done | `ARCHITECTURE.md` v3.0 |
| Research document | âœ… Done | `RESEARCH.md` |
| README updated | âœ… Done | Added architecture links |
| GitHub push | âœ… Done | 3 commits pushed |
| Issues created | âœ… Done | 8 issues (#1-#8) |
| Project CLAUDE.md | âœ… Done | This file |
| Project TRACKER.md | âœ… Done | Sprint tracking |
| Main CLAUDE.md | âœ… Done | Added Active Projects section |

**What was built:**
- Complete system architecture with mermaid diagrams
- Database schema (15+ tables)
- Event-driven architecture design
- Agent architecture with Deep Agents
- Deployment architecture with Docker Compose

**Next session:** Start Phase 1 implementation (Issues #1-#5)

---

## Project Overview

**Vision Assistant** is a complete Home AI system for smart security and family recognition.

### What's Built (v2 - Complete)
- Face recognition with auto-learning (82%+ accuracy)
- Person detection (YOLOv8n) + tracking
- Visit logging + tagging system (family/friends/public + roles)
- Voice greetings (TTS)
- VisionDB with persons, embeddings, visits tables

### What's Next (v3 - In Progress)
- Multi-camera support with unified state
- GPT-4o Vision for scene understanding
- Main Agent (Deep Agents) with tools
- Telegram bot for notifications + HITL
- House state management

---

## Architecture Overview

```mermaid
flowchart TB
    subgraph Devices["Device Layer (24/7)"]
        CAM1[Camera 1<br/>Door]
        CAM2[Camera 2<br/>Living]
        MIC[Microphone]
        SPK[Speaker]
    end

    subgraph Perception["Perception Layer (GPU)"]
        MOT[Motion<br/>Detection]
        PER[Person<br/>Detection]
        FAC[Face<br/>Recognition]
    end

    subgraph State["State Layer"]
        HS[House State]
        RS[Room States]
        CS[Camera States]
        PP[Person Presence]
    end

    subgraph Events["Event Bus"]
        EB[Priority Queue<br/>CRITICAL â†’ LOW]
    end

    subgraph Agent["Main Agent"]
        TC[Trigger Controller]
        MA[Deep Agents<br/>LLM Brain]
        TOOLS[Tools:<br/>analyze_scene<br/>speak<br/>notify]
    end

    subgraph Output["Output Layer"]
        TTS[Voice TTS]
        TG[Telegram]
        LOG[Event Log]
    end

    CAM1 --> MOT
    CAM2 --> MOT
    MOT --> PER --> FAC
    FAC --> State
    State --> EB
    EB --> TC --> MA
    MA --> TOOLS
    TOOLS --> TTS
    TOOLS --> TG
    TOOLS --> LOG
    MIC --> MA
    MA --> SPK
```

**See:** [ARCHITECTURE.md](ARCHITECTURE.md) for complete system design.

---

## Document Registry

| File | Purpose | Status |
|------|---------|--------|
| `ARCHITECTURE.md` | Complete system architecture v3.0 | âœ… Current |
| `RESEARCH.md` | Best practices research | âœ… Current |
| `TRACKER.md` | Sprint tracking and progress | âœ… Current |
| `ISSUES.md` | GitHub issues documentation | âœ… Current |
| `README.md` | Project overview + quick start | âœ… Current |
| `requirements.txt` | Python dependencies | âœ… Current |

---

## GitHub Issues

### Phase 1: Foundation (Current Sprint)
| Issue | Task | Status |
|-------|------|--------|
| [#1](https://github.com/KlementMultiverse/vision-assistant/issues/1) | Device Registry + Camera State | TODO |
| [#2](https://github.com/KlementMultiverse/vision-assistant/issues/2) | State Store with Pub/Sub | TODO |
| [#3](https://github.com/KlementMultiverse/vision-assistant/issues/3) | Event Bus | TODO |
| [#4](https://github.com/KlementMultiverse/vision-assistant/issues/4) | Database Migration | TODO |
| [#5](https://github.com/KlementMultiverse/vision-assistant/issues/5) | Pipeline Refactor | TODO |

### Phase 2: Vision Intelligence
| Issue | Task | Status |
|-------|------|--------|
| [#6](https://github.com/KlementMultiverse/vision-assistant/issues/6) | Vision Client (GPT-4o) | TODO |
| [#7](https://github.com/KlementMultiverse/vision-assistant/issues/7) | Trigger Controller | TODO |
| [#8](https://github.com/KlementMultiverse/vision-assistant/issues/8) | Main Agent (Deep Agents) | TODO |

---

## Code Structure

```
src/v2/
â”œâ”€â”€ core/                    # NEW - Core abstractions
â”‚   â”œâ”€â”€ devices.py           # Device, CameraState models
â”‚   â”œâ”€â”€ state.py             # HouseState, PersonPresence
â”‚   â””â”€â”€ events.py            # EventBus, Event types
â”‚
â”œâ”€â”€ perception/              # EXISTING - Detection modules
â”‚   â”œâ”€â”€ motion/              # Motion detection
â”‚   â”œâ”€â”€ person/              # Person detection (YOLO)
â”‚   â””â”€â”€ face/                # Face detection (InsightFace)
â”‚
â”œâ”€â”€ storage/                 # EXISTING - Database layer
â”‚   â””â”€â”€ schema.py            # VisionDB (extending)
â”‚
â”œâ”€â”€ agent/                   # NEW - LLM agent
â”‚   â”œâ”€â”€ main.py              # MainAgent (Deep Agents)
â”‚   â”œâ”€â”€ tools.py             # analyze_scene, speak, notify
â”‚   â””â”€â”€ trigger.py           # TriggerController
â”‚
â”œâ”€â”€ vision/                  # NEW - Vision API
â”‚   â”œâ”€â”€ client.py            # GPT-4o client
â”‚   â””â”€â”€ schemas.py           # VisionResult, PersonDescription
â”‚
â””â”€â”€ live_pipeline.py         # EXISTING - Main pipeline (refactoring)
```

---

## Key Design Decisions

| Decision | Why | How |
|----------|-----|-----|
| Event-Driven | Decouple perception from actions | Priority queue (CRITICAL=0 â†’ LOW=100) |
| Devices as Entities | Multi-camera support | Device registry with status, heartbeat |
| State Hierarchy | Know who's where | House â†’ Room â†’ Camera â†’ Person |
| GPT-4o Vision | Scene understanding | Structured output, dynamic prompts |
| Inside vs Outside | Different response needs | Outside=fast/paid, Inside=relaxed/free |

---

## Credentials

**Location:** `~/.claude/.env`

Contains:
- `GITHUB_TOKEN` - For git push and gh CLI
- `OPENAI_API_KEY` - For GPT-4o Vision
- `TELEGRAM_BOT_TOKEN` - For notifications (future)

---

## Running the System

### Current (v2)
```bash
source venv/bin/activate
python -m src.v2.live_pipeline
```

### Future (v3)
```bash
docker compose up -d
```

---

## Best Practices

1. **Type hints everywhere** - All dataclasses, all functions
2. **Immutable where possible** - `@dataclass(frozen=True)`
3. **Events, not callbacks** - Publish events, subscribe handlers
4. **Structured output** - Pydantic models for API responses
5. **Existing code first** - Extend VisionDB, don't replace

---

## Open Source References

- [Frigate NVR](https://github.com/blakeblackshear/frigate) - Detection pipeline, event lifecycle
- [Double Take](https://github.com/jakowenko/double-take) - Face recognition on events
- [InsightFace](https://github.com/deepinsight/insightface) - Face detection + embeddings
- [Deep Agents](https://github.com/langchain-ai/deepagents) - LLM agent framework

---

*This file helps Claude understand the project context across sessions.*
